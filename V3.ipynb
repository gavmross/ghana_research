{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model V3\n",
    "The 8 indicators being used are NDVI, rainfall, land surface temperature, soil moisture 10/40/200 cm, ndwi, and evi, plus adding yields of all crops.\n",
    "### About the Data \n",
    " - Each indicator is a mean value from June 20 to November 1 (the estimated growing season)\n",
    " - Image collections are not filtered for cloudiness upon data collection; this leaves chance for obscured numbers \n",
    " - Years are from 2000 to 2020\n",
    " - The crop yield data is only for maize \n",
    " - I control naming conventions of data from GEE, if needed I can go back and download it again\n",
    " - NDVI is a 16 day average and is prefiltered for clear images\n",
    "\n",
    " ### Improvements\n",
    "  \n",
    "TIME (2): optimize time frame to frame when indicators most impact yields\n",
    " - adjust time frame\n",
    " - maybe use subset of data, an individual year, and figure out which months are best \n",
    " - stratify by month to figure out which months are most important \n",
    "  \n",
    "CROP DATA (3)\n",
    " - add dummy variable for crop\n",
    " - standardize crop yield -- group by crop (.groupby('crop').mean()/std() to get each mean/std)\n",
    " - crop masking algorithm (4) -- only export data from areas with crops\n",
    "\n",
    "REGRESSIONS (5)\n",
    " - using lasso, elastic net, and ridge (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "import statsmodels.api as sm\n",
    "from stargazer.stargazer import Stargazer, LineLocation\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import dump, load\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Functions For Cleaning ##################\n",
    "def create_dict(dir, dict):\n",
    "    '''Params dir and dict are the directory name and dictionary to store dataframes in'''\n",
    "    for filename in os.listdir(dir):\n",
    "        fpath = os.path.join(dir, filename)         # creates the file path name\n",
    "        if os.path.isfile(fpath):                   # make sure the file is real\n",
    "            year = filename[:4]                     # year is at index 0-3 in filename\n",
    "            dict[int(year)] = pd.read_csv(fpath)    # input dictionary now has key of year and value of df for that year\n",
    "\n",
    "def reorder(dict):\n",
    "    sorted_keys = sorted(list(dict.keys()))\n",
    "    sorted_dict = {i: dict[i] for i in sorted_keys}\n",
    "    return sorted_dict\n",
    "\n",
    "def clean_dfs(dict, indicator):\n",
    "    '''dict is dictionary of dfs to clean, indicator is name value column of each df. This can\n",
    "    be found in the mean_ columns above. Last line sets index to district name to make \n",
    "    concat all dfs easier.'''\n",
    "    for k, v in dict.items():\n",
    "        year = k\n",
    "        v.drop(columns=['system:index', '.geo'], inplace=True)\n",
    "        v.rename({f'mean_{indicator}': f'{indicator}'+str(year)}, axis=1, inplace=True)\n",
    "        v.set_index(['district_name'], inplace=True)\n",
    "\n",
    "################## Uploading Files ##################\n",
    "# name directories in file path \n",
    "ndvi_dir = 'mean_ndvi'\n",
    "lst_dir = 'mean_lst'\n",
    "rain_dir = 'mean_rainfall'\n",
    "sm_10_dir = 'mean_soil_moisture_10cm'\n",
    "sm_40_dir = 'mean_soil_moisture_40cm'\n",
    "sm_200_dir = 'mean_soil_moisture_200cm'\n",
    "ndwi_dir = 'mean_ndwi'\n",
    "evi_dir = 'mean_evi'\n",
    "# create dictionaries to store each individual df\n",
    "ndvi_dict = {}\n",
    "lst_dict = {}\n",
    "rain_dict = {}\n",
    "sm_10_dict = {}\n",
    "sm_40_dict = {}\n",
    "sm_200_dict = {}\n",
    "ndwi_dict = {}\n",
    "evi_dict = {}\n",
    "\n",
    "yields = pd.read_excel('/Users/gavmross/Desktop/School/cua_spring_23/ghana/MOFA_YieldData_Maize.xlsx')\n",
    "key = pd.read_excel(\"/Users/gavmross/Desktop/School/cua_spring_23/ghana/DistrictKey.xlsx\")\n",
    "\n",
    "################## Cleaning Indicator Data ##################\n",
    "# create dictionaries with k:v = year:dataframe of that year/indicator\n",
    "create_dict(ndvi_dir, ndvi_dict)\n",
    "create_dict(lst_dir, lst_dict)\n",
    "create_dict(rain_dir, rain_dict)\n",
    "create_dict(sm_10_dir, sm_10_dict)\n",
    "create_dict(sm_40_dir, sm_40_dict)\n",
    "create_dict(sm_200_dir, sm_200_dict)\n",
    "create_dict(ndwi_dir, ndwi_dict)\n",
    "create_dict(evi_dir, evi_dict)\n",
    "\n",
    "# reorder dict keys chronologically \n",
    "ndvi_dict = reorder(ndvi_dict)\n",
    "lst_dict = reorder(lst_dict)\n",
    "rain_dict = reorder(rain_dict)\n",
    "sm_10_dict = reorder(sm_10_dict)\n",
    "sm_40_dict = reorder(sm_40_dict)\n",
    "sm_200_dict = reorder(sm_200_dict)\n",
    "ndwi_dict = reorder(ndwi_dict)\n",
    "evi_dict = reorder(evi_dict)\n",
    "\n",
    "# clean dfs\n",
    "clean_dfs(ndvi_dict, 'ndvi')\n",
    "clean_dfs(lst_dict, 'lst')\n",
    "clean_dfs(rain_dict, 'rain')\n",
    "clean_dfs(sm_10_dict, 'soil_moisture_10cm')\n",
    "clean_dfs(sm_40_dict, 'soil_moisture_40cm')\n",
    "clean_dfs(sm_200_dict, 'soil_moisture_200cm')\n",
    "clean_dfs(ndwi_dict, 'ndwi')\n",
    "clean_dfs(evi_dict, 'evi')\n",
    "\n",
    "# create one dataframe for each indicator\n",
    "ndvi_df = pd.concat(ndvi_dict.values(), axis=1)\n",
    "lst_df = pd.concat(lst_dict.values(), axis=1)\n",
    "rain_df = pd.concat(rain_dict.values(), axis=1)\n",
    "sm_10_df = pd.concat(sm_10_dict.values(), axis=1)\n",
    "sm_40_df = pd.concat(sm_40_dict.values(), axis=1)\n",
    "sm_200_df = pd.concat(sm_200_dict.values(), axis=1)\n",
    "ndwi_df = pd.concat(ndwi_dict.values(), axis=1)\n",
    "evi_df = pd.concat(evi_dict.values(), axis=1)\n",
    "\n",
    "# drop Tempane because it is not included in Yield data\n",
    "rain_df.drop(\"Tempane\", inplace=True)\n",
    "ndvi_df.drop(\"Tempane\", inplace=True)\n",
    "lst_df.drop(\"Tempane\", inplace=True)\n",
    "sm_10_df.drop(\"Tempane\", inplace=True)\n",
    "sm_40_df.drop(\"Tempane\", inplace=True)\n",
    "sm_200_df.drop(\"Tempane\", inplace=True)\n",
    "ndwi_df.drop(\"Tempane\", inplace=True)\n",
    "evi_df.drop(\"Tempane\", inplace=True)\n",
    "\n",
    "# turn dfs from wide to long format\n",
    "ndvi_df.reset_index(inplace=True)\n",
    "ndvi_final = pd.wide_to_long(ndvi_df, 'ndvi', 'district_name', 'year')\n",
    "lst_df.reset_index(inplace=True)\n",
    "lst_final = pd.wide_to_long(lst_df, 'lst', 'district_name', 'year')\n",
    "rain_df.reset_index(inplace=True)\n",
    "rain_final = pd.wide_to_long(rain_df, 'rain', 'district_name', 'year')\n",
    "sm_10_df.reset_index(inplace=True)\n",
    "sm10_final = pd.wide_to_long(sm_10_df, 'soil_moisture_10cm', 'district_name', 'year')\n",
    "sm_40_df.reset_index(inplace=True)\n",
    "sm40_final = pd.wide_to_long(sm_40_df, 'soil_moisture_40cm', 'district_name', 'year')\n",
    "sm_200_df.reset_index(inplace=True)\n",
    "sm200_final = pd.wide_to_long(sm_200_df, 'soil_moisture_200cm', 'district_name', 'year')\n",
    "ndwi_df.reset_index(inplace=True)\n",
    "ndwi_final = pd.wide_to_long(ndwi_df, 'ndwi', 'district_name', 'year')\n",
    "evi_df.reset_index(inplace=True)\n",
    "evi_final = pd.wide_to_long(evi_df, 'evi', 'district_name', 'year')\n",
    "\n",
    "# merge indicators dfs into one df \n",
    "indic_df = ndvi_final.join([lst_final, rain_final, sm10_final, sm40_final, sm200_final, ndwi_final, evi_final])\n",
    "\n",
    "################## Cleaning Yield Data ##################\n",
    "# drop district in yield data not in indicator data\n",
    "yields = yields[yields['DistID'] !=38]\n",
    "\n",
    "# rename key columns\n",
    "key.rename({\"Dist\": \"District ID\", 'Unnamed: 1': \"District Name\"}, inplace=True, axis=1)\n",
    "\n",
    "#create mapper for district ID and district naem\n",
    "mapper = dict(zip(key['District ID'], key['District Name']))\n",
    "\n",
    "# map district name to district ID\n",
    "yields['DistName'] = yields['DistID'].map(mapper)\n",
    "yields = yields[['DistID', 'DistName', 'Year', 'Yield', 'Crop']]        # reorder columns\n",
    "yields.drop(['Crop', 'DistID'], axis=1, inplace=True)                   # once i have mapped names, do not need ID anymore\n",
    "\n",
    "# sort by year then name to get it in same format as indicator df\n",
    "yields_sort = yields.sort_values(by=['Year', 'DistName'])\n",
    "# rename to have same naming conventions as other dfs\n",
    "yields_final = yields_sort.rename({'DistName': 'district_name', 'Year': 'year', 'Yield': 'yield'}, axis=1)\n",
    "\n",
    "# final df is only 2000 to 2020\n",
    "yields_final = yields_final.loc[(yields_final['year'] > 1999) & (yields_final['year'] < 2021)]\n",
    "yields_final.reset_index(inplace=True, drop=True)\n",
    "\n",
    "################## Combine Indicator and Yield Data ##################\n",
    "# rest index first to order it properly \n",
    "indic_df.reset_index(inplace=True)\n",
    "# strip all space from district names to make naming convention same as yield data\n",
    "indic_df['district_name'] = indic_df['district_name'].str.replace(' ', '')\n",
    "# sort by year and district name to make it same as yield \n",
    "indic_final = indic_df.sort_values(by=['year', 'district_name'])\n",
    "# reset indices so merging can take place\n",
    "yields_final.reset_index(drop=True, inplace=True)\n",
    "indic_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a dictionary that is k:v = indic_names:yields_names for comparison purposes \n",
    "# save indicator and yield data district names to compare\n",
    "indic_names = indic_final['district_name'].unique()\n",
    "yields_names = yields_final['district_name'].unique()\n",
    "# turn dict into df for filtering purposes (could just turn series into df)\n",
    "name_dict = dict(zip(indic_names, yields_names))\n",
    "name_df = pd.DataFrame.from_dict(name_dict, orient='index')\n",
    "name_df.reset_index(inplace=True)\n",
    "name_df.columns=['indic', 'yield']\n",
    "name_df.loc[name_df['indic'] != name_df['yield']]                       # filter for names that do not match \n",
    "\n",
    "# add yield col into indicator df\n",
    "indic_final['yield'] = yields_final['yield']\n",
    "indic_final\n",
    "\n",
    "################## Prep Data for Model ##################\n",
    "# rename to model df\n",
    "model_df = indic_final\n",
    "#sns.pairplot(model_df)\n",
    "\n",
    "# cannot have NAs in ML model, for now just going to drop it but can come up with better solution\n",
    "model_df.isna().sum()\n",
    "# drop rows with na in them, lost 153 rows \n",
    "model_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n7/vdk0hv_11kd1w3g8ssnm0nj40000gn/T/ipykernel_2913/3931489945.py:13: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the function.\n",
      "  all_yield['Standardize Yield'] = all_yield.groupby('CropName').transform(lambda x: (x - x.mean())/x.std())['Yield']     # standardize yields\n"
     ]
    }
   ],
   "source": [
    "# all yield data \n",
    "all_yield = pd.read_excel('/Users/gavmross/Desktop/school/cua_spring_23/ghana/MOFA_YieldData.xlsx')\n",
    "all_yield = all_yield[all_yield['DistID'] !=38]\n",
    "#create mapper for district ID and district naem\n",
    "mapper = dict(zip(key['District ID'], key['District Name']))\n",
    "crop_map = {1: 'Maize', 2:\"Crop2\", 3:\"Crop3\", 4:\"Crop4\", 5:\"Crop5\"}\n",
    "\n",
    "# map district name to district ID\n",
    "all_yield['DistName'] = all_yield['DistID'].map(mapper)\n",
    "all_yield['CropName'] = all_yield['Crop'].map(crop_map)\n",
    "all_yield = all_yield[['DistID', 'DistName', 'Year', 'Yield', 'Crop', 'CropName']]        # reorder columns\n",
    "all_yield.drop(['DistID'], axis=1, inplace=True)                   # once i have mapped names, do not need ID anymore\n",
    "all_yield['Standardize Yield'] = all_yield.groupby('CropName').transform(lambda x: (x - x.mean())/x.std())['Yield']     # standardize yields\n",
    "all_yield = all_yield.loc[(all_yield['Year'] > 1999) & (all_yield['Year'] < 2021)]      # filter for correct years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_name</th>\n",
       "      <th>year</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>lst</th>\n",
       "      <th>rain</th>\n",
       "      <th>soil_moisture_10cm</th>\n",
       "      <th>soil_moisture_40cm</th>\n",
       "      <th>soil_moisture_200cm</th>\n",
       "      <th>ndwi</th>\n",
       "      <th>evi</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [district_name, year, ndvi, lst, rain, soil_moisture_10cm, soil_moisture_40cm, soil_moisture_200cm, ndwi, evi, yield]\n",
       "Index: []"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## create df for each crop ##############\n",
    "maize = all_yield[all_yield[\"CropName\"]== \"Maize\"][\"Standardize Yield\"]\n",
    "crop2 = all_yield[all_yield['CropName'] == \"Crop2\"][\"Standardize Yield\"]\n",
    "crop3 = all_yield[all_yield['CropName'] == \"Crop3\"][\"Standardize Yield\"]\n",
    "crop4 = all_yield[all_yield['CropName'] == \"Crop4\"][\"Standardize Yield\"]\n",
    "crop5 = all_yield[all_yield['CropName'] == \"Crop5\"][\"Standardize Yield\"]\n",
    "############## make yield of each individual df the yield for that crop ##########\n",
    "maize_df = indic_final.copy()\n",
    "crop2_df = indic_final.copy()\n",
    "crop3_df = indic_final.copy()\n",
    "crop4_df = indic_final.copy()\n",
    "crop5_df = indic_final.copy()\n",
    "maize_df[\"yield\"] = maize\n",
    "crop2_df['yield'] = crop2\n",
    "crop3_df['yield'] = crop3\n",
    "crop4_df['yield'] = crop4\n",
    "crop5_df['yield'] = crop5\n",
    "############ drop na values ################\n",
    "maize_df.dropna(inplace=True)\n",
    "crop2_df.dropna(inplace=True)\n",
    "crop3_df.dropna(inplace=True)\n",
    "crop4_df.dropna(inplace=True)\n",
    "crop5_df.dropna(inplace=True)\n",
    "crop3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating dummy variable for one large df, not individual (TESTING)\n",
    "# crop_dummies = pd.get_dummies(all_yield['CropName'])\n",
    "# new_yields = all_yield.join(crop_dummies)\n",
    "# new_yields.drop(['Yield', 'Crop', 'CropName'], axis=1, inplace=True)\n",
    "# all_yields_sort = new_yields.sort_values(by=['Year', 'DistName'])\n",
    "# # rename to have same naming conventions as other dfs\n",
    "# all_yields_final = all_yields_sort.rename({'DistName': 'district_name', 'Year': 'year', 'Standardize Yield': 'yield'}, axis=1)\n",
    "\n",
    "# # final df is only 2000 to 2020\n",
    "# all_yields_final = all_yields_final.loc[(all_yields_final['year'] > 1999) & (all_yields_final['year'] < 2021)]\n",
    "# all_yields_final.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIZE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest test RMSE Complexity Level:  1\n",
      "Corresponding lowest test RMSE:  1.3246797933530834\n",
      "RMSE:  1.077569696431646\n",
      "RMSE as Percent of Holdout Std:  1.0509796569774514\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:yield</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">const</td><td>-66.335<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(31.719)</td></tr><tr><td style=\"text-align:left\">evi</td><td>-1.024<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(4.053)</td></tr><tr><td style=\"text-align:left\">lst</td><td>0.001<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.001)</td></tr><tr><td style=\"text-align:left\">ndvi</td><td>0.000<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td></tr><tr><td style=\"text-align:left\">ndwi</td><td>1.947<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(1.551)</td></tr><tr><td style=\"text-align:left\">rain</td><td>-0.021<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.211)</td></tr><tr><td style=\"text-align:left\">soil_moisture_10cm</td><td>10.059<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(40.414)</td></tr><tr><td style=\"text-align:left\">soil_moisture_200cm</td><td>-11.656<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(9.344)</td></tr><tr><td style=\"text-align:left\">soil_moisture_40cm</td><td>3.401<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(35.233)</td></tr><tr><td style=\"text-align:left\">year</td><td>0.021<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.016)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>206</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.053</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.010</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>1.278 (df=196)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>1.220<sup></sup> (df=9; 196)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x142274610>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## Regression with Cross Validate Holdout ##################\n",
    "# not using district name because it is categorical\n",
    "X = maize_df.drop(['yield', 'district_name'], axis=1)\n",
    "Y = maize_df['yield']\n",
    "\n",
    "# create training and holdout\n",
    "X_train, X_holdout, Y_train, Y_holdout = train_test_split(X, Y, test_size=.1, random_state=101) # test size is smaller because it is holdout\n",
    "\n",
    "# for loop to iterate over polynomial complexity \n",
    "rmse_dict = {}\n",
    "\n",
    "for i in range(1, 7):\n",
    "    # create polynomial converter for degree in for loop \n",
    "    poly_convert = PolynomialFeatures(degree=1, include_bias=False)\n",
    "    # convert X_train into polynomial variables \n",
    "    poly_X_train = poly_convert.fit_transform(X_train)\n",
    "    # create model \n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    # create scores used in cross validation\n",
    "    scores = cross_val_score(model, poly_X_train, Y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "    # store performance metric \n",
    "    RMSE = np.sqrt(abs(scores).mean())\n",
    "    rmse_dict[i] = RMSE\n",
    "\n",
    "print(\"Lowest test RMSE Complexity Level: \", min(rmse_dict, key=rmse_dict.get))\n",
    "print(\"Corresponding lowest test RMSE: \", min(rmse_dict.values()))\n",
    "\n",
    "################## Final Model: Linear ##################\n",
    "# do not need polynomial converter cause best model is linear \n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict using holdout indpendent variables and compare Yhat with Yholdout \n",
    "Yhat_holdout = model.predict(X_holdout)\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(Y_holdout, Yhat_holdout))\n",
    "print(\"RMSE: \", RMSE)\n",
    "print(\"RMSE as Percent of Holdout Std: \", RMSE/Y_holdout.std())\n",
    "\n",
    "################## Output Regression Results ##################\n",
    "model_sm = sm.OLS(endog=Y, exog=sm.add_constant(X)).fit()\n",
    "table = Stargazer([model_sm])\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROP2 REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest test RMSE Complexity Level:  1\n",
      "Corresponding lowest test RMSE:  1.071057513047699\n",
      "RMSE:  0.8648373792383048\n",
      "RMSE as Percent of Holdout Std:  1.1215114158816022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:yield</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">const</td><td>-36.004<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(36.916)</td></tr><tr><td style=\"text-align:left\">evi</td><td>0.562<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(4.578)</td></tr><tr><td style=\"text-align:left\">lst</td><td>-0.002<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.001)</td></tr><tr><td style=\"text-align:left\">ndvi</td><td>0.000<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td></tr><tr><td style=\"text-align:left\">ndwi</td><td>-1.273<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(1.414)</td></tr><tr><td style=\"text-align:left\">rain</td><td>-0.195<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.248)</td></tr><tr><td style=\"text-align:left\">soil_moisture_10cm</td><td>-28.110<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(39.976)</td></tr><tr><td style=\"text-align:left\">soil_moisture_200cm</td><td>14.548<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(11.219)</td></tr><tr><td style=\"text-align:left\">soil_moisture_40cm</td><td>17.797<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(37.908)</td></tr><tr><td style=\"text-align:left\">year</td><td>0.033<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.020)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>105</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.090</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.004</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>1.002 (df=95)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>1.041<sup></sup> (df=9; 95)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x14215f390>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## Regression with Cross Validate Holdout ##################\n",
    "# not using district name because it is categorical\n",
    "X = crop2_df.drop(['yield', 'district_name'], axis=1)\n",
    "Y = crop2_df['yield']\n",
    "\n",
    "# create training and holdout\n",
    "X_train, X_holdout, Y_train, Y_holdout = train_test_split(X, Y, test_size=.1, random_state=101) # test size is smaller because it is holdout\n",
    "\n",
    "# for loop to iterate over polynomial complexity \n",
    "rmse_dict = {}\n",
    "\n",
    "for i in range(1, 7):\n",
    "    # create polynomial converter for degree in for loop \n",
    "    poly_convert = PolynomialFeatures(degree=1, include_bias=False)\n",
    "    # convert X_train into polynomial variables \n",
    "    poly_X_train = poly_convert.fit_transform(X_train)\n",
    "    # create model \n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    # create scores used in cross validation\n",
    "    scores = cross_val_score(model, poly_X_train, Y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "    # store performance metric \n",
    "    RMSE = np.sqrt(abs(scores).mean())\n",
    "    rmse_dict[i] = RMSE\n",
    "\n",
    "print(\"Lowest test RMSE Complexity Level: \", min(rmse_dict, key=rmse_dict.get))\n",
    "print(\"Corresponding lowest test RMSE: \", min(rmse_dict.values()))\n",
    "\n",
    "################## Final Model: Linear ##################\n",
    "# do not need polynomial converter cause best model is linear \n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict using holdout indpendent variables and compare Yhat with Yholdout \n",
    "Yhat_holdout = model.predict(X_holdout)\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(Y_holdout, Yhat_holdout))\n",
    "print(\"RMSE: \", RMSE)\n",
    "print(\"RMSE as Percent of Holdout Std: \", RMSE/Y_holdout.std())\n",
    "\n",
    "################## Output Regression Results ##################\n",
    "model_sm = sm.OLS(endog=Y, exog=sm.add_constant(X)).fit()\n",
    "table = Stargazer([model_sm])\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROP3 REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m Y \u001b[39m=\u001b[39m crop3_df[\u001b[39m'\u001b[39m\u001b[39myield\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[39m# create training and holdout\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X_train, X_holdout, Y_train, Y_holdout \u001b[39m=\u001b[39m train_test_split(X, Y, test_size\u001b[39m=\u001b[39;49m\u001b[39m.1\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m101\u001b[39;49m) \u001b[39m# test size is smaller because it is holdout\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# for loop to iterate over polynomial complexity \u001b[39;00m\n\u001b[1;32m     10\u001b[0m rmse_dict \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ghana_env/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m   2564\u001b[0m )\n\u001b[1;32m   2566\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m   2567\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ghana_env/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2233\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[1;32m   2235\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2240\u001b[0m     )\n\u001b[1;32m   2242\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "################## Regression with Cross Validate Holdout ##################\n",
    "# not using district name because it is categorical\n",
    "X = crop3_df.drop(['yield', 'district_name'], axis=1)\n",
    "Y = crop3_df['yield']\n",
    "\n",
    "# create training and holdout\n",
    "X_train, X_holdout, Y_train, Y_holdout = train_test_split(X, Y, test_size=.1, random_state=101) # test size is smaller because it is holdout\n",
    "\n",
    "# for loop to iterate over polynomial complexity \n",
    "rmse_dict = {}\n",
    "\n",
    "for i in range(1, 7):\n",
    "    # create polynomial converter for degree in for loop \n",
    "    poly_convert = PolynomialFeatures(degree=1, include_bias=False)\n",
    "    # convert X_train into polynomial variables \n",
    "    poly_X_train = poly_convert.fit_transform(X_train)\n",
    "    # create model \n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    # create scores used in cross validation\n",
    "    scores = cross_val_score(model, poly_X_train, Y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "    # store performance metric \n",
    "    RMSE = np.sqrt(abs(scores).mean())\n",
    "    rmse_dict[i] = RMSE\n",
    "\n",
    "print(\"Lowest test RMSE Complexity Level: \", min(rmse_dict, key=rmse_dict.get))\n",
    "print(\"Corresponding lowest test RMSE: \", min(rmse_dict.values()))\n",
    "\n",
    "################## Final Model: Linear ##################\n",
    "# do not need polynomial converter cause best model is linear \n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict using holdout indpendent variables and compare Yhat with Yholdout \n",
    "Yhat_holdout = model.predict(X_holdout)\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(Y_holdout, Yhat_holdout))\n",
    "print(\"RMSE: \", RMSE)\n",
    "print(\"RMSE as Percent of Holdout Std: \", RMSE/Y_holdout.std())\n",
    "\n",
    "################## Output Regression Results ##################\n",
    "model_sm = sm.OLS(endog=Y, exog=sm.add_constant(X)).fit()\n",
    "table = Stargazer([model_sm])\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROP4 REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest test RMSE Complexity Level:  1\n",
      "Corresponding lowest test RMSE:  0.9447997290182859\n",
      "RMSE:  0.9476988551940423\n",
      "RMSE as Percent of Holdout Std:  1.1278995939098027\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:yield</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">const</td><td>-128.585<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(23.133)</td></tr><tr><td style=\"text-align:left\">evi</td><td>-2.883<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(2.793)</td></tr><tr><td style=\"text-align:left\">lst</td><td>0.001<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.001)</td></tr><tr><td style=\"text-align:left\">ndvi</td><td>0.000<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td></tr><tr><td style=\"text-align:left\">ndwi</td><td>1.654<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(1.159)</td></tr><tr><td style=\"text-align:left\">rain</td><td>-0.021<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.141)</td></tr><tr><td style=\"text-align:left\">soil_moisture_10cm</td><td>-6.344<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(25.390)</td></tr><tr><td style=\"text-align:left\">soil_moisture_200cm</td><td>1.541<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(7.388)</td></tr><tr><td style=\"text-align:left\">soil_moisture_40cm</td><td>1.659<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(23.666)</td></tr><tr><td style=\"text-align:left\">year</td><td>0.056<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.013)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>208</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.163</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.125</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.924 (df=198)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>4.299<sup>***</sup> (df=9; 198)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x144af7610>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## Regression with Cross Validate Holdout ##################\n",
    "# not using district name because it is categorical\n",
    "X = crop4_df.drop(['yield', 'district_name'], axis=1)\n",
    "Y = crop4_df['yield']\n",
    "\n",
    "# create training and holdout\n",
    "X_train, X_holdout, Y_train, Y_holdout = train_test_split(X, Y, test_size=.1, random_state=101) # test size is smaller because it is holdout\n",
    "\n",
    "# for loop to iterate over polynomial complexity \n",
    "rmse_dict = {}\n",
    "\n",
    "for i in range(1, 7):\n",
    "    # create polynomial converter for degree in for loop \n",
    "    poly_convert = PolynomialFeatures(degree=1, include_bias=False)\n",
    "    # convert X_train into polynomial variables \n",
    "    poly_X_train = poly_convert.fit_transform(X_train)\n",
    "    # create model \n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    # create scores used in cross validation\n",
    "    scores = cross_val_score(model, poly_X_train, Y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "    # store performance metric \n",
    "    RMSE = np.sqrt(abs(scores).mean())\n",
    "    rmse_dict[i] = RMSE\n",
    "\n",
    "print(\"Lowest test RMSE Complexity Level: \", min(rmse_dict, key=rmse_dict.get))\n",
    "print(\"Corresponding lowest test RMSE: \", min(rmse_dict.values()))\n",
    "\n",
    "################## Final Model: Linear ##################\n",
    "# do not need polynomial converter cause best model is linear \n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict using holdout indpendent variables and compare Yhat with Yholdout \n",
    "Yhat_holdout = model.predict(X_holdout)\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(Y_holdout, Yhat_holdout))\n",
    "print(\"RMSE: \", RMSE)\n",
    "print(\"RMSE as Percent of Holdout Std: \", RMSE/Y_holdout.std())\n",
    "\n",
    "################## Output Regression Results ##################\n",
    "model_sm = sm.OLS(endog=Y, exog=sm.add_constant(X)).fit()\n",
    "table = Stargazer([model_sm])\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROP5 REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest test RMSE Complexity Level:  1\n",
      "Corresponding lowest test RMSE:  0.8931680746445795\n",
      "RMSE:  0.6890763799207489\n",
      "RMSE as Percent of Holdout Std:  1.0177470067850718\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:yield</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">const</td><td>-20.375<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(23.900)</td></tr><tr><td style=\"text-align:left\">evi</td><td>1.882<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(2.918)</td></tr><tr><td style=\"text-align:left\">lst</td><td>-0.002<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.001)</td></tr><tr><td style=\"text-align:left\">ndvi</td><td>-0.000<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td></tr><tr><td style=\"text-align:left\">ndwi</td><td>-0.193<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(1.418)</td></tr><tr><td style=\"text-align:left\">rain</td><td>0.149<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.157)</td></tr><tr><td style=\"text-align:left\">soil_moisture_10cm</td><td>-20.236<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(30.306)</td></tr><tr><td style=\"text-align:left\">soil_moisture_200cm</td><td>-10.882<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(9.467)</td></tr><tr><td style=\"text-align:left\">soil_moisture_40cm</td><td>30.994<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(31.404)</td></tr><tr><td style=\"text-align:left\">year</td><td>0.027<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.012)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>166</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.102</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.050</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.838 (df=156)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>1.962<sup>**</sup> (df=9; 156)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x14235a190>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## Regression with Cross Validate Holdout ##################\n",
    "# not using district name because it is categorical\n",
    "X = crop5_df.drop(['yield', 'district_name'], axis=1)\n",
    "Y = crop5_df['yield']\n",
    "\n",
    "# create training and holdout\n",
    "X_train, X_holdout, Y_train, Y_holdout = train_test_split(X, Y, test_size=.1, random_state=101) # test size is smaller because it is holdout\n",
    "\n",
    "# for loop to iterate over polynomial complexity \n",
    "rmse_dict = {}\n",
    "\n",
    "for i in range(1, 7):\n",
    "    # create polynomial converter for degree in for loop \n",
    "    poly_convert = PolynomialFeatures(degree=1, include_bias=False)\n",
    "    # convert X_train into polynomial variables \n",
    "    poly_X_train = poly_convert.fit_transform(X_train)\n",
    "    # create model \n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    # create scores used in cross validation\n",
    "    scores = cross_val_score(model, poly_X_train, Y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "    # store performance metric \n",
    "    RMSE = np.sqrt(abs(scores).mean())\n",
    "    rmse_dict[i] = RMSE\n",
    "\n",
    "print(\"Lowest test RMSE Complexity Level: \", min(rmse_dict, key=rmse_dict.get))\n",
    "print(\"Corresponding lowest test RMSE: \", min(rmse_dict.values()))\n",
    "\n",
    "################## Final Model: Linear ##################\n",
    "# do not need polynomial converter cause best model is linear \n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predict using holdout indpendent variables and compare Yhat with Yholdout \n",
    "Yhat_holdout = model.predict(X_holdout)\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(Y_holdout, Yhat_holdout))\n",
    "print(\"RMSE: \", RMSE)\n",
    "print(\"RMSE as Percent of Holdout Std: \", RMSE/Y_holdout.std())\n",
    "\n",
    "################## Output Regression Results ##################\n",
    "model_sm = sm.OLS(endog=Y, exog=sm.add_constant(X)).fit()\n",
    "table = Stargazer([model_sm])\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ghana_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "856fc35d0aadd12116d58878105b2e14050acbd1369d0e1604998027ec499ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
